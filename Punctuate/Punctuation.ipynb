{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install tensorflow[and-cuda]\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# c2 = 0\n",
    "# punctuations = ['.', ',', '?', '!']\n",
    "# tokens = [ \"[FULLSTOP]\", \"[COMMA]\", \"[QUESTIONMARK]\", \"[EXCLAMATIONMARK]\" ]\n",
    "# with open( \"eng_sentences.tsv\" ) as file:\n",
    "#     with open( \"eng_out.txt\", \"w\" ) as w_file:\n",
    "#         for line in file.readlines():\n",
    "#             out = \"[START] \"\n",
    "#             sentence = line.split(\"\\t\")[2][:-1]\n",
    "#             words = sentence.split(\" \")\n",
    "#             # print(words)\n",
    "#             for word in words:\n",
    "#                 # print(word[-1])\n",
    "#                 if( word[-1] in punctuations ):\n",
    "#                     count = count +1 \n",
    "#                     out = out + tokens[punctuations.index(word[-1])] + \" \"\n",
    "#                 else:\n",
    "#                     out = out + \"[SPACE] \"\n",
    "#             out = out + \"[END]\"\n",
    "#             out = out + \"\\n\"\n",
    "#             c2 = c2 +1\n",
    "#             print(c2)\n",
    "#             w_file.write(out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 23:09:50.582747: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-16 23:09:50.666624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-16 23:09:50.688295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-16 23:09:50.760465: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-16 23:09:52.028682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from Utils import Dataset\n",
    "from Transformer import Transformer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# from focal_loss import SparseCategoricalFocalLoss\n",
    "INP_MAX_LENGTH = 50\n",
    "OUT_MAX_LENGTH = 50\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723829993.004357  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.222072  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.222168  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.227200  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.227295  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.227322  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.536920  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1723829993.537048  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-16 23:09:53.537060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1723829993.537147  713178 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-16 23:09:53.537219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-08-16 23:10:24.183741: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-16 23:10:44.868347: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    ds = Dataset(\"eng_sentences.tsv\", \"eng_out.txt\", INP_MAX_LENGTH, OUT_MAX_LENGTH, BATCH_SIZE, BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches, test_batches = ds.get_data_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It was kind of scary                                             '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (s,t), t_in  in train_batches.take(1):\n",
    "    break\n",
    "\n",
    "ds.decode_input(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SPACE] [SPACE] [SPACE] [SPACE] [FULLSTOP] [END]                                           '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.decode_output(t_in[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[START] [SPACE] [SPACE] [SPACE] [SPACE] [FULLSTOP] [END]                                          '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.decode_output(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.get_output_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "a = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_crossentropy_masked(y_true, y_pred):\n",
    "    y_true_masked = tf.boolean_mask(y_true, tf.not_equal(y_true, 0))\n",
    "    y_pred_masked = tf.boolean_mask(y_pred, tf.not_equal(y_true, 0))\n",
    "    return K.mean(K.sparse_categorical_crossentropy(y_true_masked, y_pred_masked))\n",
    "\n",
    "def masked_accuracy(y_true, y_pred):\n",
    "    a.reset_state()\n",
    "    # Create a mask for non-padded tokens\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    y_pred = tf.argmax(y_pred, axis = 1)\n",
    "    # Apply the mask to both predictions and true labels\n",
    "    masked_y_true = tf.boolean_mask(y_true, mask)\n",
    "    masked_y_pred = tf.boolean_mask(y_pred, mask)\n",
    "    a.update_state( masked_y_true, masked_y_pred )\n",
    "    # Calculate accuracy based on non-padded tokens\n",
    "    return a.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    num_layers = 2\n",
    "    d_model = 128\n",
    "    dense_hidden_num_units = 64\n",
    "    num_heads = 6\n",
    "\n",
    "    transformer = Transformer(num_layers, d_model, num_heads, dense_hidden_num_units, ds.get_input_vocab_size(), ds.get_output_vocab_size(), INP_MAX_LENGTH, OUT_MAX_LENGTH)\n",
    "\n",
    "    checkpoint_filepath = \"./tmp/model/cp-{epoch:04d}.weights.h5\"\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_freq=\"epoch\",\n",
    "        save_best_only=True)\n",
    "\n",
    "    callback_list = [ model_checkpoint_callback ]\n",
    "    \n",
    "    transformer.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = transformer.fit(\n",
    "        train_batches,\n",
    "        callbacks = callback_list ,\n",
    "        epochs=20,\n",
    "        validation_data=test_batches\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedEntityRecognizer(tf.Module):\n",
    "  def __init__(self, transformer):\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=OUT_MAX_LENGTH):\n",
    "    sentence = ds.vectorize(sentence)\n",
    "    # print(sentence)\n",
    "    encoder_input = sentence\n",
    "\n",
    "    start_end = ds.encode_label([\"[START]\",\"[END]\"])\n",
    "    start = start_end[0][0][tf.newaxis]\n",
    "    end = start_end[1][0][tf.newaxis]\n",
    "    # print(start)\n",
    "\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "      \n",
    "      predictions = predictions[:, -1:, :]  \n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    text = [ds.decode_output(out) for out in output]\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = NamedEntityRecognizer(transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Grandmother looks very comfortable in that chair beside the fire                                                                                                                                                                                              ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'encoder_self_attention_16' (of type EncoderSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'sequential_32' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'feed_forward_32' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'encoder_layer_16' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'encoder_self_attention_17' (of type EncoderSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'sequential_33' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'feed_forward_33' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'encoder_layer_17' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 6, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'causal_self_attention_16' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'cross_attention_16' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'sequential_34' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'feed_forward_34' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'decoder_layer_16' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'causal_self_attention_17' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'cross_attention_17' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'sequential_35' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'feed_forward_35' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/shriyam/ASR/Punctuate/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'decoder_layer_17' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 51), dtype=int64, numpy=\n",
       "array([[3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 0, 2, 5, 4, 0, 2, 5, 4, 0, 2,\n",
       "        5, 4, 0, 2, 2, 2, 2, 2, 2, 5, 4, 0, 2, 5, 4, 0, 2, 5, 4, 0, 2, 2,\n",
       "        5, 4, 0, 2, 2, 2, 2]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (s,t), t_l in train_batches.take(1):\n",
    "    break\n",
    "\n",
    "sentence = [ds.decode_input(s[4])]\n",
    "print(sentence)\n",
    "\n",
    "translated_text = translator(\n",
    "    sentence\n",
    ")\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 0, 2, 5, 4, 0, 2, 5, 4, 0, 2, 5,\n",
       "       4, 0, 2, 2, 2, 2, 2, 2, 5, 4, 0, 2, 5, 4, 0, 2, 5, 4, 0, 2, 2, 5,\n",
       "       4, 0, 2, 2, 2])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_l[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(49,), dtype=int64, numpy=\n",
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_l[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " '[SPACE]',\n",
       " '[START]',\n",
       " '[END]',\n",
       " '[FULLSTOP]',\n",
       " '[QUESTIONMARK]',\n",
       " '[COMMA]',\n",
       " '[EXCLAMATIONMARK]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.output_vectorizer.get_vocabulary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
